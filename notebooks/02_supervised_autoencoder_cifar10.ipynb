{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervised Autoencoder on CIFAR-10 — Notebook Template\n",
        "\n",
        "**Goal:** Train a supervised autoencoder (reconstruction + classification) on CIFAR-10, with clear verification at each step.\n",
        "\n",
        "> Fill in the TODOs step-by-step. Each section contains a brief checklist and sanity checks.\n",
        "\n",
        "_Generated: 2025-10-21T11:48:40.685883Z_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Environment & Reproducibility\n",
        "- [ ] Select device (CPU/GPU)\n",
        "- [ ] Set random seeds\n",
        "- [ ] (Optional) Enable cudnn benchmark\n",
        "\n",
        "**Verify:** print device; run a tiny tensor op."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# TODO: imports\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# TODO: set device and seeds\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Config\n",
        "- [ ] Define a simple config dict (dataset paths, batch size, latent_dim, λ, lr)\n",
        "- [ ] Print config to confirm\n",
        "\n",
        "**Tip:** Start simple; you can move this to YAML later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "da16c83a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'augment': True,\n",
            " 'batch_size': 128,\n",
            " 'data_root': '../data_02',\n",
            " 'epochs': 50,\n",
            " 'img_size': 32,\n",
            " 'lambda_recon': 0.25,\n",
            " 'latent_dim': 64,\n",
            " 'lr': 0.001,\n",
            " 'num_workers': 4,\n",
            " 'weight_decay': 0.0001}\n"
          ]
        }
      ],
      "source": [
        "# TODO: create a minimal config\n",
        "CONFIG = {\n",
        "    'data_root': '../data_02',\n",
        "    'batch_size': 128,\n",
        "    'augment': True,\n",
        "    'num_workers': 4,\n",
        "    'img_size': 32,\n",
        "    'latent_dim': 64,          # try 32/128 later\n",
        "    'lambda_recon': 0.25,      # weight for reconstruction loss\n",
        "    'lr': 1e-3,\n",
        "    'weight_decay': 1e-4,\n",
        "    'epochs': 50,\n",
        "}\n",
        "from pprint import pprint\n",
        "pprint(CONFIG)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4b13d73",
      "metadata": {},
      "source": [
        "## 2) Data Pipeline (CIFAR-10)\n",
        "- [ ] Define train/val/test transforms\n",
        "- [ ] Build DataLoaders\n",
        "- [ ] Print batch shapes and pixel ranges\n",
        "\n",
        "**Verify:** `(B, 3, 32, 32)` and labels shape `(B,)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "52ffaa62",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 117M/170M [03:53<01:45, 504kB/s]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 59\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loader, test_loader\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# TODO: after implementing, run a quick sanity batch\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# ex:\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# train_loader, val_loader, test_loader = get_dataloaders(CONFIG)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# images, labels = next(iter(train_loader))\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# print(images.shape, labels.shape, images.min().item(), images.max().item())\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m train_loader, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(images\u001b[38;5;241m.\u001b[39mshape, labels\u001b[38;5;241m.\u001b[39mshape, images\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem(), images\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem())\n",
            "Cell \u001b[0;32mIn[5], line 34\u001b[0m, in \u001b[0;36mget_dataloaders\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_dataloaders\u001b[39m(cfg) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mobject\u001b[39m, \u001b[38;5;28mobject\u001b[39m, \u001b[38;5;28mobject\u001b[39m]:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# TODO: use torchvision.datasets.CIFAR10 and DataLoader\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# return train_loader, val_loader, test_loader\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     train_tfms, test_tfms \u001b[38;5;241m=\u001b[39m get_transforms(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maugment\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 34\u001b[0m     train_set \u001b[38;5;241m=\u001b[39m \u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_root\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_tfms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     test_set \u001b[38;5;241m=\u001b[39m CIFAR10(root\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_root\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     39\u001b[0m                             train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     40\u001b[0m                             transform\u001b[38;5;241m=\u001b[39m test_tfms, \n\u001b[1;32m     41\u001b[0m                             download \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mtrain_set, \n\u001b[1;32m     44\u001b[0m                              batch_size\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     45\u001b[0m                              num_workers\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m] )\n",
            "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.10/site-packages/torchvision/datasets/cifar.py:66\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.10/site-packages/torchvision/datasets/cifar.py:139\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.10/site-packages/torchvision/datasets/utils.py:388\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    386\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 388\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    391\u001b[0m extract_archive(archive, extract_root, remove_finished)\n",
            "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.10/site-packages/torchvision/datasets/utils.py:127\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# download the file\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.10/site-packages/torchvision/datasets/utils.py:30\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     31\u001b[0m             fh\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     32\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
            "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m~/anaconda3/envs/m3/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# TODO: implement get_transforms(augment=True/False) and get_dataloaders()\n",
        "from typing import Tuple\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "def get_transforms(augment: bool = True):\n",
        "    # TODO: import torchvision.transforms as T and define train/test transforms\n",
        "    # return train_tfms, test_tfms\n",
        "    # Keep inputs in [0,1] with sigmoid at the decoder-> no normalisation\n",
        "    train_tfms = T.Compose([\n",
        "        T.RandomCrop(32, padding=4),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.ToTensor(),\n",
        "        ])\n",
        "    \n",
        "    test_val_tfms = T.Compose([\n",
        "            T.ToTensor(),\n",
        "        ])\n",
        "    \n",
        "    if augment is True:\n",
        "        return train_tfms, test_val_tfms\n",
        "    \n",
        "    else:\n",
        "        train_tfms = test_val_tfms\n",
        "        return train_tfms, test_val_tfms\n",
        "        \n",
        "def get_dataloaders(cfg) -> Tuple[object, object, object]:\n",
        "    # TODO: use torchvision.datasets.CIFAR10 and DataLoader\n",
        "    # return train_loader, val_loader, test_loader\n",
        "    train_tfms, test_tfms = get_transforms(cfg['augment'])\n",
        "    \n",
        "    train_set = CIFAR10(root=cfg['data_root'], train=True, transform= train_tfms, download = True)\n",
        "    test_set = CIFAR10(root=cfg['data_root'], train=False, transform= test_tfms, download = True)\n",
        "    \n",
        "    train_loader = DataLoader(dataset=train_set, batch_size=cfg[\"batch_size\"], num_workers=cfg[\"num_workers\"])\n",
        "    test_loader = DataLoader(dataset=test_set, batch_size=cfg[\"batch_size\"], num_workers=cfg[\"num_workers\"])\n",
        "    \n",
        "    return train_loader, test_loader\n",
        "\n",
        "# TODO: after implementing, run a quick sanity batch\n",
        "# ex:\n",
        "# train_loader, val_loader, test_loader = get_dataloaders(CONFIG)\n",
        "# images, labels = next(iter(train_loader))\n",
        "# print(images.shape, labels.shape, images.min().item(), images.max().item())\n",
        "\n",
        "train_loader, test_loader = get_dataloaders(CONFIG)\n",
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape, labels.shape, images.min().item(), images.max().item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Model — Encoder, Decoder, Classifier Head, SupervisedAE\n",
        "- [ ] Implement `Encoder` → `z`\n",
        "- [ ] Implement `Decoder` ← `z`\n",
        "- [ ] Implement `ClassifierHead` (MLP on `z` → 10 logits)\n",
        "- [ ] Implement `SupervisedAE.forward(x) → (z, x_hat, logits)`\n",
        "\n",
        "**Verify:** Check shapes for a dummy batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: define the model classes (use small CNN blocks suitable for CIFAR-10)\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim: int = 64):\n",
        "        super().__init__()\n",
        "        # TODO: conv → bn → relu blocks with downsampling to small spatial map\n",
        "        # self.feature_extractor = ...\n",
        "        # self.to_latent = nn.Linear(flat_dim, latent_dim)\n",
        "        raise NotImplementedError('Build the Encoder')\n",
        "    def forward(self, x):\n",
        "        # TODO: return z of shape (B, latent_dim)\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim: int = 64):\n",
        "        super().__init__()\n",
        "        # TODO: linear → reshape → convtranspose blocks back to (B,3,32,32)\n",
        "        raise NotImplementedError('Build the Decoder')\n",
        "    def forward(self, z):\n",
        "        # TODO: return x_hat in [0,1] if using BCE, or unbounded for MSE\n",
        "        raise NotImplementedError\n",
        "\n",
        "class ClassifierHead(nn.Module):\n",
        "    def __init__(self, latent_dim: int = 64, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        # TODO: MLP on z → logits\n",
        "        raise NotImplementedError('Build the ClassifierHead')\n",
        "    def forward(self, z):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class SupervisedAE(nn.Module):\n",
        "    def __init__(self, latent_dim: int = 64, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        # TODO: compose encoder, decoder, head\n",
        "        raise NotImplementedError('Assemble SupervisedAE')\n",
        "    def forward(self, x):\n",
        "        # TODO: return z, x_hat, logits\n",
        "        raise NotImplementedError\n",
        "\n",
        "# TODO: sanity check shapes with a dummy input once implemented\n",
        "# x = torch.randn(8, 3, CONFIG['img_size'], CONFIG['img_size']).to(device)\n",
        "# model = SupervisedAE(CONFIG['latent_dim']).to(device)\n",
        "# with torch.no_grad():\n",
        "#     z, x_hat, logits = model(x)\n",
        "# print(z.shape, x_hat.shape, logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Losses\n",
        "- [ ] Reconstruction loss (MSE or BCE)\n",
        "- [ ] Classification loss (CrossEntropy)\n",
        "- [ ] Total loss = CE + λ * Recon (+ optional L2 on z)\n",
        "\n",
        "**Verify:** scalar outputs; grads flow to encoder/decoder/head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: implement loss functions\n",
        "def reconstruction_loss(x_hat, x, loss_type='mse'):\n",
        "    # TODO: return mse or bce\n",
        "    raise NotImplementedError\n",
        "\n",
        "def classification_loss(logits, y):\n",
        "    # TODO: return cross entropy\n",
        "    raise NotImplementedError\n",
        "\n",
        "def total_loss(logits, x_hat, y, x, lambda_recon: float = 0.25, loss_type='mse'):\n",
        "    # TODO: combine\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Training Loop\n",
        "- [ ] Build optimizer + (optional) scheduler\n",
        "- [ ] Train for N epochs, log running losses & accuracy\n",
        "- [ ] Validate each epoch; keep best checkpoint\n",
        "\n",
        "**Verify:** both CE and recon losses decrease; accuracy > random."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: implement train_one_epoch, evaluate, fit\n",
        "def train_one_epoch(model, loader, optimizer, cfg):\n",
        "    # TODO: loop over batches; compute losses; backprop; return logs\n",
        "    raise NotImplementedError\n",
        "\n",
        "def evaluate(model, loader, cfg):\n",
        "    # TODO: compute val accuracy and recon loss\n",
        "    raise NotImplementedError\n",
        "\n",
        "def fit(model, train_loader, val_loader, cfg):\n",
        "    # TODO: manage epochs, checkpoint best model\n",
        "    raise NotImplementedError\n",
        "\n",
        "# TODO: run training once everything above is ready\n",
        "# model = SupervisedAE(CONFIG['latent_dim']).to(device)\n",
        "# opt = torch.optim.Adam(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
        "# history = fit(model, train_loader, val_loader, CONFIG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Evaluation & Visual Checks\n",
        "- [ ] Test accuracy (top-1, optionally top-5)\n",
        "- [ ] Reconstruction quality (grid of originals vs reconstructions)\n",
        "- [ ] Extract latents `z` and visualize (PCA/UMAP/t-SNE)\n",
        "\n",
        "**Verify:** supervised AE should show more separated clusters than AE-only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: implement helper functions\n",
        "def test_accuracy(model, loader):\n",
        "    # TODO: compute top-1 accuracy\n",
        "    raise NotImplementedError\n",
        "\n",
        "def show_reconstructions(model, loader, n=8):\n",
        "    # TODO: create and display/save a grid of reconstructions\n",
        "    raise NotImplementedError\n",
        "\n",
        "def extract_latents(model, loader):\n",
        "    # TODO: concatenate z and labels\n",
        "    raise NotImplementedError\n",
        "\n",
        "def plot_latent_2d(Z, y, method='pca'):\n",
        "    # TODO: reduce to 2D and plot (matplotlib)\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Ablations & Baselines\n",
        "- [ ] Classifier-only baseline (λ=0; no decoder)\n",
        "- [ ] AE-only baseline (train AE, then MLP on frozen z)\n",
        "- [ ] Supervised AE (main), sweep λ ∈ {0.1, 0.25, 0.5, 1.0}, latent_dim ∈ {32,64,128}\n",
        "\n",
        "**Record:** accuracy, recon MSE, and latent plots per setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Logging & Checkpoints\n",
        "- [ ] Save per-epoch metrics (CSV/JSON)\n",
        "- [ ] Save best model by val accuracy\n",
        "- [ ] (Optional) TensorBoard\n",
        "\n",
        "**Verify:** resume training from checkpoint works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Notes & Next Steps\n",
        "- Try label smoothing, dropout, or weight decay tweaks\n",
        "- Try different reconstruction loss (BCE vs MSE)\n",
        "- Try data augmentation on/off\n",
        "- Try OOD score via distance to class centroids in latent space\n",
        "- Consider VAE version (KL term) once supervised AE is stable"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "m3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
